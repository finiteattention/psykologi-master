{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh14000\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Teaser: cognitive bias\
\
\'abCognitive bias, bias or systematic error in perception, assessment and decision. Cognitive bias is often studied in situations where people make spontaneous assessments of information. "Https://en.wikipedia.org/wiki/Cognitive_bias\
\
It's always useful to use metacognition, which is just a fancy way of saying that being conscious of yourself and how you are feeling and thinking can be very helpful. Being aware of cognitive bias makes it easier to understand when we fall prey to it, and reminds us to strive for asking good questions, and having in place good practices and other things that could reduce the effects. For example, one kind of bias is that we prefer "people like us\'bb, which is exactly why it's so critical to have the right things in place before hiring so we don\'92t limit diversity without even realising it.\
\
At the same time, it\'92s not necessarily desirable to point at others and say \'abin this particular case, you have displayed cognitive bias\'bb. Better maybe to ask constructive questions and figure it out together, and to try and understand why someone is saying what they are or behaving the way they are. \
\
Since Knut asked (but also because I think it will be interesting and useful :) soon there will be posts about what kind of cognitive bias could affect meetings, and everything that happens there. The ways people perceive information, agree/disagree, and make decisions - per the definition above, \'abspontaneously assess information."\
\
Below are some suggestions - this list certainly does not cover everything, so please add your own suggestions and/or observations/opinions/etc.\
\
https://en.wikipedia.org/wiki/List_of_cognitive_biases\
\
\

\b The ambiguity effect 
\b0 https://en.wikipedia.org/wiki/Ambiguity_effect \

\b \

\b0 People prefer choices in which the outcome is known over choices where the outcome is unknown, even though the latter may come with a much less reward. This is about people generally prefering certainty. In English you would say "Better the devil you know than the devil you don\'92t\'bb.\
\
Internal example: we opt for a technology that we have used before, which is (only) satisfactory, rather than one that may have more benefits, but which we have not used before.\
\
Potential solution: try to understand outcomes of choosing the unknown technology; try the technology in a pilot or on a small project and/or one with low risk.\
\
External example: the customer chooses waterfall rather than agile development, because they prefer that something is delivered on a particular date, even though it may not be the right thing.\
\
Potential solution: try to identify useful outcome of the unknown choice; work hard to reassure/increase certainty elsewhere, so that some uncertainty is better tolerated.\
\
To avoid this bias, we could:\
- be aware of when we ourselves are experiencing uncertainty\
- notice those times when we make choices while using the words "clearly" and "obviously"\
- try to hold ourselves open to opportunities a bit longer than we usually would, or than is comfortable\
\

\b Anchoring effect 
\b0 https://en.wikipedia.org/wiki/Anchoring\
\
People place too much emphasis on an early piece of information, such that it affects the scope of later assessments and guesses. This happens without us knowing it, and can happen even though that early detail may have little or nothing to do with subsequent information.\
\
Internal example: Someone estimates that a development task may take two weeks. Subsequently all developers base their estimates on that initial estimate.\
\
Potential solution: Use a method that allows people to estimate simultaneously (as in Rock-Paper-Scissors), and then discuss any differences that arise.\
\
External example: The customer has some previous experience of doing a thing that we are going to deliver, but their expectations are limited by that experience, and consequently our suggestion must fall quite close to their earlier experience to be accepted as "acceptable" or "realistic"\
\
Potential solution: TBD\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 To avoid this bias, we could:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 - be aware when we share numeric information, estimates, etc., and consider what future expectations we may be shaping by giving that information\
- Choose evaluation methods that can reduce the anchoring effect: simultaneous estimation, \'91vote-by-sticker' technique, etc.\
- discuss (preferably with data) how this case is different from previous examples\
\
\

\b Accessibility Heuristic
\b0  https://en.wikipedia.org/wiki/Availability_heuristic\
\
How easy it is to come up with an example of something affects your estimation as to how often it happens and / or how likely it is that it will happen. That is, we put more emphasis on recent experiences, and on those which had more consequence for us, even though these may not have been typical/common/high priority.\
\
Internal example: Something painful happened, so we have strong opinions that it should be talked about and/or fixed in preference to other things, and so we end up trying to control the direction of the discussion or work at the expense of other legitimate stuff.\
\
Potential solution: Use fair systems that ensure that everyone gets to give input, and that everyone\'92s input is given equal weight\
\
External example: The customer chooses to develop functionality that solves a problem that was recently discovered, although it is not necessarily the most important.\
\
Potential solution: Help the customer prioritize work/the backlog against things that can be measured or assessed more objectively: the cost, how many users are affected, greater uncertainty or risk in terms of technical development, etc.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 To avoid this bias, we could:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 - make sure we use the most accurate data and the right measurements when prioritizing our work\
- gather knowledge and input with techniques and tools that do not favour the loudest voices, and which don\'92t emphasise "recent" over "important"\
\
\

\b Confirmation bias
\b0  https://en.wikipedia.org/wiki/Confirmation_bias\
\
We seek evidence of the things we already believe to be true, and reject things that are not related to those. This is completely contrary to the scientific method of attempting to find evidence that would refute a theory (and unless you discover such evidence, strictly speaking, you can still only say that the theory is not disproved, not that it's definitely true).\
\
Internal example: TBD\
\
Potential solution: TBD\
\
External example: The client is more aware of, and more willing to solve, findings from user testing that support their previous understanding/opinion, than those which do not.\
\
Potential solution: Test with multiple users, agreeing the hypotheses in advance; replay all the findings, and if there are any the customer seems to ignore, use video and so on to show that this is a human being who is genuinely struggling with something, not something we just made up :)\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 To avoid this bias, we could:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 - TBD\
- TBD\
\
\

\b The Curse of Knowledge
\b0  https://en.wikipedia.org/wiki/Curse_of_knowledge\
\
We lack the ability to experience events from others' perspective, and to intuively understand that they do not know what we know. But we also don\'92t know that we lack this ability, and so others seem, from our perspective, just incredibly stupid. At the very least, we do not understand that their perspective is very different to our own, and so we struggle to communicate effectively.\
\
Example: Our client\'92s understanding is very different from their user\'92s, so the current solution is difficult to use, but the client doesn\'92t know this. It's hard to persuade the client that resources should be used to improve today's user experience, rather than to develop new functionality.\
\
Potential solution: Ask users questions in front of the customer, illustrating the differences between their and the client\'92s understanding of what is happening. Obtain clear evidence that can be used to educate the client about how much they know relative to the users, and how poorly the existing solution is understood.\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 To avoid this bias, we could:\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 - TBC\
- TBC}